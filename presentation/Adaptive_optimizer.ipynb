{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Necessary Libraries"
      ],
      "metadata": {
        "id": "aJPGYhP4f5a3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i490J_mZf0LX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load Dataset"
      ],
      "metadata": {
        "id": "ZyvtSDDTgJ2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zUdcgPxKhwnn",
        "outputId": "8e1f0e44-4d08-4c09-f9bf-1e1483664df7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= x_train.reshape(x_train.shape[0],28,28,1)\n",
        "x_test=  x_test.reshape(x_test.shape[0],28,28,1)\n",
        "input_shape=(28,28,1)\n",
        "y_train=keras.utils.to_categorical(y_train)#,num_classes=)\n",
        "y_test=keras.utils.to_categorical(y_test)#, num_classes)\n",
        "x_train= x_train.astype('float32')\n",
        "x_test= x_test.astype('float32')\n",
        "x_train /= 255 # dividing all pixel values by 255, the values are rescaled to be between 0 and 1.\n",
        "x_test /=255"
      ],
      "metadata": {
        "id": "VnCUU50GgIjn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ],
      "metadata": {
        "id": "i8JGY6E9guE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "\n",
        "num_classes=10\n",
        "\n",
        "epochs=10\n",
        "\n",
        "def build_model(optimizer):\n",
        "  model=Sequential()\n",
        "\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer= optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "FsXIbTFQgYW3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "1D7MdoJEh_5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers = ['Adagrad', 'Adam', 'RMSprop', 'SGD']\n",
        "\n",
        "# for i in optimizers:\n",
        "\n",
        "#   model = build_model(i)\n",
        "\n",
        "#   hist=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "id": "cnN_34VKiGg9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using  Tensorflow keras"
      ],
      "metadata": {
        "id": "UyXI8tq2m0Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adadelta, Adagrad, Adam, RMSprop\n",
        "import pandas as pd\n",
        "\n",
        "# Define a dictionary of optimizers\n",
        "optimizers = {\n",
        "    # 'Adadelta': Adadelta(),\n",
        "    'Adagrad': Adagrad(),\n",
        "    'Adam': Adam(),\n",
        "    'RMSprop': RMSprop(),\n",
        "    'SGD': SGD(learning_rate=0.01, momentum=0.9)  # SGD with momentum\n",
        "}\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "for name, optimizer in optimizers.items():\n",
        "    print(f\"Running optimizer: {name}\")\n",
        "    model = build_model(optimizer)\n",
        "\n",
        "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "    # Store the results for the table\n",
        "    results.append({\n",
        "        'Optimizer': name,\n",
        "        'Training Accuracy': hist.history['accuracy'][-1],\n",
        "        'Validation Accuracy': hist.history['val_accuracy'][-1],\n",
        "        'Training Loss': hist.history['loss'][-1],\n",
        "        'Validation Loss': hist.history['val_loss'][-1]\n",
        "    })\n",
        "\n",
        "# Create a DataFrame to display the results as a table\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Print the table\n",
        "print(\"\\nSummary of Optimizer Performance:\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AWCW9kKwkJoA",
        "outputId": "ad46aa7a-73d1-4d29-fc07-f76f5d0fda38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running optimizer: Adagrad\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 1.5238 - accuracy: 0.5876 - val_loss: 0.7336 - val_accuracy: 0.8493\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.7336 - accuracy: 0.7887 - val_loss: 0.4698 - val_accuracy: 0.8816\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.5695 - accuracy: 0.8325 - val_loss: 0.3900 - val_accuracy: 0.8971\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.5039 - accuracy: 0.8497 - val_loss: 0.3524 - val_accuracy: 0.9049\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.4612 - accuracy: 0.8640 - val_loss: 0.3252 - val_accuracy: 0.9122\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.4322 - accuracy: 0.8730 - val_loss: 0.3064 - val_accuracy: 0.9151\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.4107 - accuracy: 0.8786 - val_loss: 0.2913 - val_accuracy: 0.9188\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.3933 - accuracy: 0.8834 - val_loss: 0.2781 - val_accuracy: 0.9205\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3741 - accuracy: 0.8888 - val_loss: 0.2672 - val_accuracy: 0.9235\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.3654 - accuracy: 0.8920 - val_loss: 0.2581 - val_accuracy: 0.9252\n",
            "Running optimizer: Adam\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.2212 - accuracy: 0.9330 - val_loss: 0.0666 - val_accuracy: 0.9779\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0895 - accuracy: 0.9730 - val_loss: 0.0528 - val_accuracy: 0.9829\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0670 - accuracy: 0.9792 - val_loss: 0.0438 - val_accuracy: 0.9842\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0546 - accuracy: 0.9824 - val_loss: 0.0397 - val_accuracy: 0.9851\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 0.0358 - val_accuracy: 0.9875\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 0.0339 - val_accuracy: 0.9882\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.0303 - val_accuracy: 0.9894\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0316 - val_accuracy: 0.9895\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.0308 - val_accuracy: 0.9894\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0329 - val_accuracy: 0.9898\n",
            "Running optimizer: RMSprop\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2410 - accuracy: 0.9269 - val_loss: 0.0694 - val_accuracy: 0.9777\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0927 - accuracy: 0.9716 - val_loss: 0.0532 - val_accuracy: 0.9822\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0689 - accuracy: 0.9788 - val_loss: 0.0422 - val_accuracy: 0.9863\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0591 - accuracy: 0.9819 - val_loss: 0.0459 - val_accuracy: 0.9848\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 0.0381 - val_accuracy: 0.9872\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 0.0395 - val_accuracy: 0.9866\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0329 - val_accuracy: 0.9877\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.0331 - val_accuracy: 0.9891\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.0384 - val_accuracy: 0.9882\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0370 - accuracy: 0.9891 - val_loss: 0.0372 - val_accuracy: 0.9891\n",
            "Running optimizer: SGD\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.4149 - accuracy: 0.8718 - val_loss: 0.1459 - val_accuracy: 0.9558\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.1862 - accuracy: 0.9432 - val_loss: 0.0891 - val_accuracy: 0.9717\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.1285 - accuracy: 0.9616 - val_loss: 0.0699 - val_accuracy: 0.9780\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.1040 - accuracy: 0.9678 - val_loss: 0.0576 - val_accuracy: 0.9822\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0874 - accuracy: 0.9733 - val_loss: 0.0459 - val_accuracy: 0.9846\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0755 - accuracy: 0.9768 - val_loss: 0.0465 - val_accuracy: 0.9842\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0693 - accuracy: 0.9785 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0615 - accuracy: 0.9808 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0559 - accuracy: 0.9825 - val_loss: 0.0374 - val_accuracy: 0.9875\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0516 - accuracy: 0.9833 - val_loss: 0.0365 - val_accuracy: 0.9872\n",
            "\n",
            "Summary of Optimizer Performance:\n",
            "  Optimizer  Training Accuracy  Validation Accuracy  Training Loss  \\\n",
            "0   Adagrad           0.891967               0.9252       0.365410   \n",
            "1      Adam           0.991500               0.9898       0.025378   \n",
            "2   RMSprop           0.989100               0.9891       0.036995   \n",
            "3       SGD           0.983317               0.9872       0.051604   \n",
            "\n",
            "   Validation Loss  \n",
            "0         0.258074  \n",
            "1         0.032877  \n",
            "2         0.037175  \n",
            "3         0.036549  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## intrepretations\n",
        "The above table shows the validation accuracy and loss at different epochs. It also contains the total time that the model took to run on 10 epochs for each optimizer. From the above table, we can make the following analysis.\n",
        "\n",
        "The adam optimizer shows the best accuracy in a satisfactory amount of time.\n",
        "RMSprop shows similar accuracy to that of Adam but with a comparatively much larger computation time.\n",
        "Surprisingly, the SGD algorithm took the least time to train and produced good results as well. But to reach the accuracy of the Adam optimizer, SGD will require more iterations, and hence the computation time will increase.\n",
        " SGD with momentum shows similar accuracy to SGD with unexpectedly larger computation time. This means the value of momentum taken needs to be optimized.\n"
      ],
      "metadata": {
        "id": "MJwNUXie77Co"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNl8ESrM7_PG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}